{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca5f67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a44a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+xpu\n",
      "Using device: xpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import mmap\n",
    "import intel_extension_for_pytorch as ipex\n",
    "print(torch.__version__)\n",
    "device = 'xpu' if torch.xpu.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b97cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block=64\n",
    "batch=128\n",
    "max_iters=3000\n",
    "# eval_interval=500\n",
    "eval_iters=500\n",
    "learning_rate=3e-3\n",
    "n_embd = 384\n",
    "n_layer = 8\n",
    "n_head = 8\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97684dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter 1\n",
      "\n",
      "_To Mrs. Saville, England._\n",
      "\n",
      "\n",
      "St. Petersburgh, Dec. 11th, 17—.\n",
      "\n",
      "\n",
      "You will rejoice to hear that no disaster has accompanied the\n",
      "commencement of an enterprise which you have regarded with suc\n",
      "Total characters: ['\\n', ' ', '!', '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'æ', 'è', 'é', 'ê', 'ô', '—', '‘', '’', '“', '”', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "with open('vocab.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    chars = sorted(list(set(text)))\n",
    "print(text[:200])\n",
    "print(f'Total characters: {chars}')\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff264b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 51, 58, 58, 61, 1, 69, 61, 64, 58, 50]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "stringtoint={ch:i for i,ch in enumerate(chars)}\n",
    "inttostring={i:ch for i,ch in enumerate(chars)}\n",
    "encode=lambda s: [stringtoint[c] for c in s]\n",
    "decode=lambda l: ''.join([inttostring[i] for i in l])\n",
    "\n",
    "print(encode('hello world'))\n",
    "print(decode(encode('hello world')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c15328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([418920]) torch.int64\n",
      "tensor([83, 32, 51, 66, 66, 51, 64,  1,  9,  0,  0, 46, 39, 61,  1, 33, 64, 65,\n",
      "         7,  1, 38, 47, 68, 55, 58, 58, 51,  5,  1, 25, 60, 53, 58, 47, 60, 50,\n",
      "         7, 46,  0,  0,  0, 38, 66,  7,  1, 36, 51, 66, 51, 64, 65, 48, 67, 64,\n",
      "        53, 54,  5,  1, 24, 51, 49,  7,  1,  9,  9, 66, 54,  5,  1,  9, 15, 78,\n",
      "         7,  0,  0,  0, 43, 61, 67,  1, 69, 55, 58, 58,  1, 64, 51, 56, 61, 55,\n",
      "        49, 51,  1, 66, 61,  1, 54, 51, 47, 64])\n"
     ]
    }
   ],
   "source": [
    "# data = torch.tensor(encode(text), dtype=torch.long)\n",
    "# print(data.shape, data.dtype)\n",
    "# print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80487dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_chunk(split):\n",
    "    filename = 'output_train.txt' if split == 'train' else 'output_val.txt'\n",
    "    with open(filename, 'rb') as f:\n",
    "        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "            file_size = len(mm)\n",
    "            start_idx = random.randint(0, (file_size)-block*batch)\n",
    "            \n",
    "            mm.seek(start_idx)\n",
    "            chunk = mm.read(block*batch-1)\n",
    "            decoded_chunk = chunk.decode('utf-8', errors='ignore').replace('\\r', '')\n",
    "            data = torch.tensor(encode(decoded_chunk), dtype=torch.long)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc01aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([335136]) torch.Size([83784])\n",
      "inputs:\n",
      "tensor([[ 1, 48, 71,  ..., 60, 51, 65],\n",
      "        [65,  1, 52,  ...,  1, 51, 60],\n",
      "        [55, 72, 61,  ..., 65,  1, 61],\n",
      "        ...,\n",
      "        [61, 52,  1,  ..., 55, 66, 54],\n",
      "        [60, 61, 66,  ..., 55, 59, 62],\n",
      "        [50,  1, 54,  ..., 55, 58, 61]], device='xpu:0')\n",
      "targets:\n",
      "tensor([[48, 71,  1,  ..., 51, 65, 65],\n",
      "        [ 1, 52, 55,  ..., 51, 60, 49],\n",
      "        [72, 61, 60,  ...,  1, 61, 64],\n",
      "        ...,\n",
      "        [52,  1, 66,  ..., 66, 54,  1],\n",
      "        [61, 66,  1,  ..., 59, 62, 51],\n",
      "        [ 1, 54, 51,  ..., 58, 61, 65]], device='xpu:0')\n"
     ]
    }
   ],
   "source": [
    "# n=int(0.8*len(data))\n",
    "# train_data = data[:n]\n",
    "# val_data = data[n:]\n",
    "# print(train_data.shape, val_data.shape)\n",
    "\n",
    "def get_batch(split):\n",
    "    data = get_random_chunk(split)\n",
    "    ix = torch.randint(len(data) - block,(batch,))\n",
    "    # print(ix)\n",
    "    x = torch.stack([data[i:i+block] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block+1] for i in ix])\n",
    "    x=x.to(device); y=y.to(device)\n",
    "    return x,y \n",
    "\n",
    "x,y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82407314",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block, block)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a45bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for i in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size*num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cdf7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe4642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x+y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x+y)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ccd99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iê“S;lcFle0O0Sækq,3  s!m”pgmPO]oTj(B:cl6:K!!ybw—‘8ObxG]êuJ5;8æ”yl,7yr(lLMcFwLLfpe1æTA”’6_sFqTfCDF)H“CvJMh‘roj‘Mé;:n\n",
      "êP?rTw68RæELDiUY(L5NB]‘-”Jv—é;46V!L2)RyWæCVæwé)(E8N4Bé?bC?FêSèUNcghqCMD9:nEOx:t\n",
      "é(F8(lyAVq!,6ESvPFM95GGrNær,\n",
      "9PyrJ7;g7uN?lEUFèo?bèc1[ôb;”,é— sFyA17“(l3HADvC ;wha(?;wk0euRrR np5’DUhUC;U,(W2\n",
      ";trBô6An6(M:k.p;xjCeFôgMxzGbbp1r“x)x GCB]uxyE?—eH( ]2f6’“[L\n",
      "n[l1;Fqhw?NePmJlFM2— ixo-x2c),æUgUrô1,ceNcm]zWB[x“é8n.Le 6HV(dAnAq.S9m(G.(NL“C)4.;F6ezl4HKdFG;FnPl(p“Vé)nYMIrBu _)HN5é“ô7dD“nmyUo)Ow(éê\n"
     ]
    }
   ],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for i in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        # self.apply(self._init_weights)\n",
    "        \n",
    "        def _init_weights(self, module):\n",
    "            if isinstance(module, nn.Linear):\n",
    "                torch.nn.init.normal_(model.weight, mean=0.0, std=0.02)\n",
    "                if module.bias is not None:\n",
    "                    torch.nn.init.zeros_(module.bias)\n",
    "                elif isinstance(module, nn.Embedding):\n",
    "                    torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        # logits = self.token_embedding_table(idx)\n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits=logits.view(B*T,C)\n",
    "            targets=targets.view(B*T)\n",
    "            loss=F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for i in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block:]\n",
    "            logits, loss = self.forward(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs =F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=-1)\n",
    "        return idx\n",
    "    \n",
    "model = GPTLanguageModel(vocab_size)\n",
    "print('Model instance created.')\n",
    "MODEL_PATH = 'gpt1_model.pth'\n",
    "\n",
    "# --- New Loading Block ---\n",
    "try:\n",
    "    # Load the saved state_dict\n",
    "    # We use map_location to ensure the model loads correctly\n",
    "    # onto the device you've chosen (e.g., 'xpu' or 'cpu').\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    print('Model weights loaded.')\n",
    "except FileNotFoundError:\n",
    "    print('No saved model found. Starting from scratch.')\n",
    "# -------------------------\n",
    "\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81021300",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out={}\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses=torch.zeros(eval_iters)\n",
    "        for i in range(eval_iters):\n",
    "            X,Y=get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[i]=loss.item()\n",
    "        out[split]=losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d25b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.5882, val loss 4.5895\n",
      "step 500: train loss 3.0537, val loss 3.0494\n",
      "step 1000: train loss 3.0521, val loss 3.0483\n",
      "step 1500: train loss 3.0527, val loss 3.0473\n",
      "step 2000: train loss 3.0513, val loss 3.0468\n",
      "step 2500: train loss 3.0441, val loss 3.0443\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iteration in range(max_iters):\n",
    "    if iteration%eval_iters==0:\n",
    "        losses=estimate_loss()\n",
    "        print(f\"step {iteration}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    \n",
    "    xb,yb=get_batch('train')\n",
    "    \n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "# print(loss.item())\n",
    "MODEL_PATH = 'gpt1_model.pth'\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcc-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
